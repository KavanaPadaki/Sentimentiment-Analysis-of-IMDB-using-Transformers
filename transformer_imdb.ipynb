{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())  # Should be True\n",
        "print(torch.cuda.get_device_name(0))  # Shows GPU name"
      ],
      "metadata": {
        "id": "XCBs9aymM12s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding"
      ],
      "metadata": {
        "id": "KXluC0COIX41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"imdb\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")"
      ],
      "metadata": {
        "id": "bexkicshIew2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(batch):\n",
        "  return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=512)"
      ],
      "metadata": {
        "id": "Z0vyg4E2Ioao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
        "tokenized_dataset.set_format(\"torch\",columns=[\"input_ids\", \"attention_mask\", \"label\"])"
      ],
      "metadata": {
        "id": "5WS9pyjFI_dI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\",num_labels = 2)"
      ],
      "metadata": {
        "id": "XmpzkpF_JMMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir = \"./logs\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    learning_rate=2e-5,  # or use `accelerate` to auto-detect\n",
        "    fp16=True\n",
        "    )"
      ],
      "metadata": {
        "id": "KDt32OPJJVB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    train_dataset = tokenized_dataset[\"train\"],\n",
        "    eval_dataset = tokenized_dataset[\"test\"],\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        ")"
      ],
      "metadata": {
        "id": "fcSRU-EpJzG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "iTCAX0G5KD7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"distilbert-imdb-finetuned\")\n"
      ],
      "metadata": {
        "id": "EsXNWtLn4rrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub(\"KavanaPadaki/distilbert-imdb\")"
      ],
      "metadata": {
        "id": "nn7k82CR4xES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline(\"text-classification\", model=\"path-or-hub-name\")"
      ],
      "metadata": {
        "id": "o_K652GG42KE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return accuracy_metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "9Z_xbzjyx-2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = trainer.predict(tokenized_dataset[\"test\"])\n",
        "acc = accuracy_metric.compute(\n",
        "    predictions=np.argmax(predictions.predictions, axis=-1),\n",
        "    references=predictions.label_ids\n",
        ")\n",
        "print(f\"Validation Accuracy: {acc['accuracy']:.4f}\")"
      ],
      "metadata": {
        "id": "8oD2lZxd70kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_metric = evaluate.load(\"f1\")\n",
        "precision_metric = evaluate.load(\"precision\")\n",
        "recall_metric = evaluate.load(\"recall\")"
      ],
      "metadata": {
        "id": "W-NgemLm79JW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score = f1_metric.compute(predictions=np.argmax(predictions.predictions, axis=-1), references=predictions.label_ids)\n",
        "precision_score = precision_metric.compute(predictions=np.argmax(predictions.predictions, axis=-1), references=predictions.label_ids)\n",
        "recall_score = recall_metric.compute(predictions=np.argmax(predictions.predictions, axis=-1), references=predictions.label_ids)"
      ],
      "metadata": {
        "id": "j5vsSUdl8Z4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Validation F1 Score: {f1_score['f1']:.4f}\")\n",
        "print(f\"Validation Precision Score: {precision_score['precision']:.4f}\")\n",
        "print(f\"Validation Recall Score: {recall_score['recall']:.4f}\")"
      ],
      "metadata": {
        "id": "6C_y9qtB8mmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load your fine-tuned model from local folder or Hugging Face Hub\n",
        "MODEL_NAME = \"KavanaPadaki/distilbert-imdb\"  # or \"./distilbert-imdb-finetuned\"\n",
        "classifier = pipeline(\"text-classification\", model=MODEL_NAME)\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"ðŸŽ¬ IMDb Sentiment Classifier\")\n",
        "st.write(\"Enter a movie review and see if it's positive or negative.\")\n",
        "\n",
        "# Text input\n",
        "user_input = st.text_area(\"Movie Review\", height=150)\n",
        "\n",
        "if st.button(\"Classify\"):\n",
        "    if user_input.strip():\n",
        "        result = classifier(user_input, truncation=True, max_length=512)[0]\n",
        "        label = result['label']\n",
        "        score = result['score']\n",
        "        st.markdown(f\"**Prediction:** {label}\")\n",
        "        st.markdown(f\"**Confidence:** {score:.2%}\")\n",
        "    else:\n",
        "        st.warning(\"Please enter a review before classifying.\")"
      ],
      "metadata": {
        "id": "dGPUFk318tiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IgP54sEN9t53"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}